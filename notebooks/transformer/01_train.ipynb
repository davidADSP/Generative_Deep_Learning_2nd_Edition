{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# ðŸš€ Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863c414-1946-4482-b0d0-1552ee5ffd41",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Parameters](#parameters)\n",
    "1. [Load the Data](#load)\n",
    "2. [Tokensise the Data](#tokenise)\n",
    "3. [Create the Training Set](#create)\n",
    "4. [Build the LSTM](#build)\n",
    "5. [Train the LSTM](#train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dca6836-0007-43f3-af65-d12ae1922c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0d56cc-4773-4029-97d8-26f882ba79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8352af-343e-4c2e-8c91-95f8bac1c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 80\n",
    "EMBEDDING_DIM = 256\n",
    "N_HEADS = 2\n",
    "FEED_FORWARD_DIM = 256\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7716fac-0010-49b0-b98e-53be2259edde",
   "metadata": {},
   "source": [
    "## 1. Load the data <a name=\"load\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93cf6b0f-9667-4146-8911-763a8a2925d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Â Load the full dataset\n",
    "with open('/app/data/wine-reviews/winemag-data-130k-v2.json') as json_data:\n",
    "    wine_data = json.load(json_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db5c0fc-0d5f-42ab-ade1-57e594c416ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'points': '87',\n",
       " 'title': 'Kirkland Signature 2011 Mountain CuvÃ©e Cabernet Sauvignon (Napa Valley)',\n",
       " 'description': 'Soft, supple plum envelopes an oaky structure in this Cabernet, supported by 15% Merlot. Coffee and chocolate complete the picture, finishing strong at the end, resulting in a value-priced wine of attractive flavor and immediate accessibility.',\n",
       " 'taster_name': 'Virginie Boone',\n",
       " 'taster_twitter_handle': '@vboone',\n",
       " 'price': 19,\n",
       " 'designation': 'Mountain CuvÃ©e',\n",
       " 'variety': 'Cabernet Sauvignon',\n",
       " 'region_1': 'Napa Valley',\n",
       " 'region_2': 'Napa',\n",
       " 'province': 'California',\n",
       " 'country': 'US',\n",
       " 'winery': 'Kirkland Signature'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a74eca-f1b7-4a46-9a1f-b5806a4ed361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the dataset\n",
    "filtered_data = [x['title'] \\\n",
    "                 + '\\n' + x['country'] + ' : ' + x['province']  + ' : ' + x['variety'] + \\\n",
    "                 '\\n' + x['description'] \\\n",
    "            for x in wine_data\n",
    "              if x['title'] is not None\n",
    "              and x['country'] is not None\n",
    "                 and x['province'] is not None\n",
    "                 and x['variety'] is not None\n",
    "                 and x['description'] is not None\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "389c20de-0422-4c48-a7b4-6ee12a7bf0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129907 recipes loaded\n"
     ]
    }
   ],
   "source": [
    "# Count the recipes\n",
    "n_wines = len(filtered_data)\n",
    "print(f'{n_wines} recipes loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2e3cf7-e416-460e-874a-0dd9637bca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Castello di Amorosa 2011 King Ridge Vineyard Pinot Noir (Sonoma Coast)\n",
      "US : California : Pinot Noir\n",
      "Oak and earth intermingle around robust aromas of wet forest floor in this vineyard-designated Pinot that hails from a high-elevation site. Small in production, it offers intense, full-bodied raspberry and blackberry steeped in smoky spice and smooth texture.\n"
     ]
    }
   ],
   "source": [
    "example = filtered_data[25]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f871aaf-d873-41c7-8946-e4eef7ac17c1",
   "metadata": {},
   "source": [
    "## 2. Tokenise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2064fb-5dcc-4657-b470-0928d10e2ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pad the punctuation, to treat them as separate 'words'  \n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}, '\\n'])\", r' \\1 ', s)\n",
    "    s = re.sub(' +', ' ', s)\n",
    "    return s\n",
    "\n",
    "text_data = [pad_punctuation(x) for x in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b87d7c65-9a46-492a-a5c0-a043b0d252f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jean - Baptiste Adam 2012 Les Natures Pinot Gris ( Alsace ) \\n France : Alsace : Pinot Gris \\n This has great depth of flavor with its fresh apple and pear fruits and touch of spice . It ' s off dry while balanced with acidity and a crisp texture . Drink now . \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display an example of a recipe\n",
    "example_data = text_data[9]\n",
    "example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9834f916-b21a-4104-acc9-f28d3bd7a8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 18:52:24.070019: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Convert to a Tensorflow Dataset\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(text_data).batch(BATCH_SIZE).shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884c0bcb-0807-45a1-8f7e-a32f2c6fa4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorisation layer\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize = 'lower',\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",=\n",
    "    output_sequence_length=MAX_LEN + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6dd34a-d905-497b-926a-405380ebcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the layer to the training set\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6c1c7ce-3cf0-40d4-a3dc-ab7090f69f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: [UNK]\n",
      "2: ,\n",
      "3: .\n",
      "4: and\n",
      "5: :\n",
      "6: the\n",
      "7: a\n",
      "8: of\n",
      "9: )\n"
     ]
    }
   ],
   "source": [
    "# Display some token:word mappings\n",
    "for i, word in enumerate(vocab[:10]):\n",
    "    print(f'{i}: {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc30186-7ec6-4eb6-b29a-65df6714d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 881   13 4696 3175   70  417    1   31  291   10  212    9   48    5\n",
      "  212    5   31  291   12   49  210  411    8  166   11   61   63   79\n",
      "    4  130   80    4  121    8   55    3   15   17   22  268   53   93\n",
      "  122   11   34    4    7   85   91    3   40   74    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Display the same example converted to ints\n",
    "example_tokenised = vectorize_layer(example_data)\n",
    "print(example_tokenised.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c195efb-84c6-4be0-a989-a7542188ad35",
   "metadata": {},
   "source": [
    "## 3. Create the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740294a1-1a6b-4c89-92f2-036d7d1b788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training set of recipes and the same text shifted by one word\n",
    "def prepare_inputs(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "train_ds = text_ds.map(prepare_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff50401-3abe-4c10-bba8-b35bc13ad7d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Build the Transformer <a name=\"build\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9230b5bf-b4a8-48d5-b73b-6899a598f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    \"\"\"\n",
    "    Mask the upper half of the dot product matrix in self attention.\n",
    "    This prevents flow of information from future tokens to current token.\n",
    "    1's in the lower triangle, counting from the lower right corner.\n",
    "    \"\"\"\n",
    "    i = tf.range(n_dest)[:, None]\n",
    "    j = tf.range(n_src)\n",
    "    m = i >= j - n_src + n_dest\n",
    "    mask = tf.cast(m, dtype)\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "    mult = tf.concat(\n",
    "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "    )\n",
    "    return tf.tile(mask, mult)\n",
    "\n",
    "\n",
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.att = keras.layers.MultiHeadAttention(N_HEADS, EMBEDDING_DIM)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [keras.layers.Dense(ff_dim, activation=\"relu\"), keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "        attention_output = self.att(inputs, inputs, attention_mask=causal_mask)\n",
    "        attention_output = self.dropout1(attention_output)\n",
    "        out1 = self.layernorm1(inputs + attention_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdf5cb25-88ae-4026-9e21-c1e6b5094a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size =vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"maxlen\": self.maxlen,\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8c57596e-e17d-4959-b6e8-7581b0bace3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    inputs = keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32)\n",
    "    embedding_layer = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBEDDING_DIM)\n",
    "    x = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(EMBEDDING_DIM, N_HEADS, FEED_FORWARD_DIM)\n",
    "    x = transformer_block(x)\n",
    "    outputs = keras.layers.Dense(VOCAB_SIZE, activation = 'softmax')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=[outputs, x])\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(\n",
    "        \"adam\", loss=[loss_fn, None],\n",
    "    )  # No loss and optimization based on word embeddings from transformer block\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a1c3b0f-3382-444d-bb04-bae143ae5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 80)]              0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, 80, 256)          2580480   \n",
      " g_5 (TokenAndPositionEmbedd                                     \n",
      " ing)                                                            \n",
      "                                                                 \n",
      " transformer_block_4 (Transf  (None, 80, 256)          658688    \n",
      " ormerBlock)                                                     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 80, 10000)         2570000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,809,168\n",
      "Trainable params: 5,809,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "800a3c6e-fb11-4792-b6bc-9a43a7c977ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    # model.load_weights('./models/model')\n",
    "    model = keras.models.load_model('./models/model', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b14665-4359-447b-be58-3fd58ba69084",
   "metadata": {},
   "source": [
    "## 3. Train the LSTM <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ddcff5f-829d-4449-99d2-9a3cb68f7d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TextGenerator checkpoint\n",
    "class TextGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self, index_to_word, top_k=10):\n",
    "        self.index_to_word = index_to_word\n",
    "        self.word_to_index = {word: index for index, word in enumerate(index_to_word)}\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs), probs \n",
    "    \n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [self.word_to_index.get(x, 1) for x in start_prompt.split()]\n",
    "        sample_token = None\n",
    "        info = []\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
    "            pad_len = MAX_LEN - len(start_tokens)\n",
    "            sample_index = len(start_tokens) - 1\n",
    "            if pad_len < 0:\n",
    "                x = start_tokens[:MAX_LEN]\n",
    "                sample_index = MAX_LEN - 1\n",
    "            elif pad_len > 0:\n",
    "                x = start_tokens + [0] * pad_len\n",
    "            else:\n",
    "                x = start_tokens\n",
    "            x = np.array([x])\n",
    "            y, _ = self.model.predict(x, verbose = 0)\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
    "            info.append({'prompt': start_prompt , 'word_probs': probs})\n",
    "            start_tokens.append(sample_token)\n",
    "            start_prompt = start_prompt + ' ' + self.index_to_word[sample_token]\n",
    "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.generate(\"\", max_tokens = 100, temperature = 1.0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "349865fe-ffbe-450e-97be-043ae1740e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model save checkpoint\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "# Tokenize starting prompt\n",
    "text_generator = TextGenerator(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "461c2b3e-b5ae-4def-8bd9-e7bab8c63d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 135/4060 [..............................] - ETA: 39:44 - loss: 3.9364 - dense_14_loss: 3.9364"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# steps_per_epoch = 3,\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_generator\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds, \n",
    "    epochs=25, \n",
    "    # steps_per_epoch = 3,\n",
    "    callbacks = [model_checkpoint_callback, tensorboard_callback, text_generator]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369bde44-2e39-4bc6-8549-a3a27ecce55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save(\"./models/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64e02d2-84dc-40c8-8446-40c09adf1e20",
   "metadata": {},
   "source": [
    "# 3. Generate text using the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad23adb-3ec9-4e9a-9a59-b9f9bafca649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probs(info, vocab, top_k = 5):\n",
    "    for i in info:\n",
    "        print(f\"\\nPROMPT: {i['prompt']}\")\n",
    "        word_probs = i['word_probs']\n",
    "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
    "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
    "        for p, i in zip(p_sorted, i_sorted):\n",
    "            print(f'{vocab[i]}:   \\t{np.round(100*p,2)}%') \n",
    "        print('--------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf25578-d47c-4b26-8252-fcdf2316a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = text_generator.generate(\"recipe for roasted vegetables | chop 1 /\", max_tokens = 10, temperature = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df72866-b483-4489-8e26-d5e1466410fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e1fe8-cbcb-438f-9637-2f2a6279c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = text_generator.generate(\"recipe for roasted vegetables | chop 1 /\", max_tokens = 10, temperature = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56356f21-04ac-40e5-94ff-291eca6a7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e434497-07f3-4989-a68d-3e31cf8fa4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = text_generator.generate(\"recipe for chocolate ice cream |\", max_tokens = 7, temperature = 1.0)\n",
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011cd0e0-956c-4a63-8ec3-f7dfed31764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = text_generator.generate(\"recipe for chocolate ice cream |\", max_tokens = 7, temperature = 0.2)\n",
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115c29d-c538-4db6-aa31-debbb829b691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9dca7-edb0-45f3-b44f-ecfae4d5c170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc4d16-6895-40e0-bf85-ffad038925d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
